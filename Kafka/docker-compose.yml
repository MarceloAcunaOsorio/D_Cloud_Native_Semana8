#Paso 1: Crear docker-compose.yml
# Tener instalado VS Studio Code
# Tener instalado Docker Desktop

version: '3'

services:
  # Zookeeper 1 (Leader)
  zookeeper-1:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper-1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: "zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888"
    volumes:
      - zookeeper-data-1:/var/lib/zookeeper
    networks:
      - kafka-net

  # Zookeeper 2 (Follower)
  zookeeper-2:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper-2
    ports:
      - "2182:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: "zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888"
    volumes:
      - zookeeper-data-2:/var/lib/zookeeper
    networks:
      - kafka-net

  # Zookeeper 3 (Follower)
  zookeeper-3:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper-3
    ports:
      - "2183:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: "zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888"
    volumes:
      - zookeeper-data-3:/var/lib/zookeeper
    networks:
      - kafka-net

  # Kafka 1
  kafka-1:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-1:9092"
    volumes:
      - kafka-data-1:/var/lib/kafka/data
    networks:
      - kafka-net

  # Kafka 2
  kafka-2:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-2
    ports:
      - "9093:9092"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-2:9092"
    volumes:
      - kafka-data-2:/var/lib/kafka/data
    networks:
      - kafka-net

  # Kafka 3
  kafka-3:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-3
    ports:
      - "9094:9092"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-3:9092"
    volumes:
      - kafka-data-3:/var/lib/kafka/data
    networks:
      - kafka-net

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "docker-cluster"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka-1:9092,kafka-2:9093,kafka-3:9094"
    networks:
      - kafka-net

networks:
  kafka-net:
    driver: bridge

volumes:
  zookeeper-data-1:
  zookeeper-data-2:
  zookeeper-data-3:
  kafka-data-1:
  kafka-data-2:
  kafka-data-3:
 

# Paso 2: Limpiar Contenedores y Volúmenes
# docker-compose down -v
# docker system prune -a -f
# Esto elimina todos los contenedores y volúmenes asociados, asegurando que la nueva configuración se aplique correctamente.

# Paso 3: Reiniciar el Cluster
# docker-compose up -d
# Esto descargará e iniciará los contenedores de Zookeeper, Kafka y Kafka UI.
# docker ps -a
# Si ves zookeeper-1, zookeeper-2, zookeeper-3, kafka-1, kafka-2, kafka-3 y kafka-ui en la lista, todo está funcionando.

# Paso 4: Ver Logs de Zookeeper y kafka
# docker logs zookeeper-1
# docker logs kafka-1
# Esto permite ver los logs de kafka y zookeeper para revisar errores

# Paso 5: Acceder a la Interfaz Gráfica (Kafka UI)
# http://localhost:8080
# Desde aquí puedes administrar los topics de Kafka de forma visual.

######################### PROBAR KAFKA DESDE FUERA DEL CONTENEDOR ###############################################

# Paso 6: Probar Kafka desde la Terminal de VS Code





# docker exec -it kafka-1 kafka-topics --create --topic senales_vitales --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3
# Crear un topic con 3 particiones y replicación en los 3 nodos


# docker exec -it kafka-1 kafka-topics --create --topic Alertas --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3
# Crear un topic con 3 particiones y replicación en los 3 nodos





# docker exec -it kafka-1 kafka-topics --list --bootstrap-server localhost:9092
# Listar los topics creados

# docker exec -it kafka-1 kafka-console-producer --broker-list localhost:9092 --topic mi-topic
# Enviar un mensaje al topic (Productor)

# docker exec -it kafka-2 kafka-console-consumer --bootstrap-server localhost:9093 --topic mi-topic --from-beginning
# Leer mensajes del topic (Consumidor)

# Paso 7: Apagar el Cluster
# docker-compose down
# Cuando termines de usar Kafka, puedes detener los contenedores

# Crear tópicos para señales vitales y alertas
# docker exec -it kafka-1 kafka-topics --create --topic señales_vitales --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3
# docker exec -it kafka-1 kafka-topics --create --topic alertas --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3

######################### PROBAR KAFKA DESDE ADENTRO DEL CONTEDOR ################################################

# 1 Conéctate a un contenedor de Kafka
# Para ejecutar comandos de Kafka, primero ingresa a uno de los brokers de Kafka. Por ejemplo, accede a kafka-1:
# docker exec -it kafka-1 bash
# Dentro del contenedor, ve a la carpeta donde están los scripts de Kafka:
# cd /usr/bin

# 2 Crea un tópico en Kafka
# Ejecuta el siguiente comando para crear un nuevo tópico llamado "test-topic":
# kafka-topics --create --topic test-topic --bootstrap-server kafka-1:9092 --partitions 3 --replication-factor 3
# Esto hace que: ✅ Kafka cree 3 particiones del tópico.
# ✅ Cada partición tenga copias en los 3 brokers.
# ✅ Un broker actúe como líder para cada partición.
# Para verificar que el tópico está replicado, usa:
# kafka-topics --describe --topic test-topic --bootstrap-server kafka-1:9092
# ������ Leader: Es el broker que maneja las escrituras en la partición.
# ������ Replicas: Son los brokers que tienen copias del dato.
# ������ Isr (In-Sync Replicas): Brokers que están sincronizados con el líder.
# Para verificar que el tópico fue creado correctamente, usa:
# kafka-topics --list --bootstrap-server kafka-1:9092
# Debe aparecer en la lista:
# test-topic

# 3 Enviar mensajes con un Producer
# Para enviar mensajes al tópico test-topic, ejecuta:
# kafka-console-producer --topic test-topic --bootstrap-server kafka-1:9092
# Se abrirá una línea donde puedes escribir mensajes. Por ejemplo, escribe:
# Hola Kafka!
# Mensaje de prueba
# Presiona Enter después de cada mensaje.

# 4 Leer mensajes con un Consumer
# Desde otra terminal en VS Code, conéctate nuevamente al contenedor:
# docker exec -it kafka-1 bash
# Ejecuta el siguiente comando para leer los mensajes enviados:
# kafka-console-consumer --topic test-topic --bootstrap-server kafka-1:9092 --from-beginning
# Deberías ver los mensajes enviados desde el Producer.

######################### HACER PRUEBAS DE FALLOS DESDE KAFKA #######################################

# Prueba de fallos
# Para probar la tolerancia a fallos, apaga un broker y verifica que los mensajes siguen disponibles:
# docker stop kafka-1
# Luego, intenta consumir mensajes desde otro broker:
# docker exec -it kafka-2 bash
# kafka-console-consumer --topic test-topic --bootstrap-server kafka-2:9092 --from-beginning
# kafka-console-consumer --topic test-topic --bootstrap-server kafka-3:9092 --from-beginning
# Si todo está bien, Kafka reasignará el líder a otro broker y seguirá funcionando. 


########################## EXPLICACIÓN COMO FUNCIONA REPLICACIÓN EN KAFKA #############################

# ������ Cómo funciona la replicación en Kafka
# Cada tópico en Kafka tiene múltiples particiones.

# Cada mensaje que envíes se almacena en una partición específica.
# Cada partición tiene un líder y seguidores en otros brokers.
